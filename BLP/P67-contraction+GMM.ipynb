{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "np.set_printoptions(legacy='1.13')\n",
    "\n",
    "tolerance = 0.00001\n",
    "multim_n_consumer = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Practice 6: Solving for Mean Utilities via Contraction Mapping\n",
    "\n",
    "### üéØ Goal\n",
    "Find the vector of mean utilities $\\delta_j$ that rationalizes observed market shares $s_j^{\\text{obs}}$,  \n",
    "by matching simulated shares $s_j^{\\text{pred}}(\\delta)$ to observed shares.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Theory\n",
    "\n",
    "Contraction mapping update rule:\n",
    "\n",
    "$$\n",
    "\\delta_j^{\\text{new}} = \\delta_j^{\\text{old}} + \\log(s_j^{\\text{obs}}) - \\log(s_j^{\\text{pred}})\n",
    "$$\n",
    "\n",
    "- Adjust $\\delta_j$ by the log difference between observed and predicted shares.\n",
    "- Repeat until $\\delta$ converges.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è Steps\n",
    "\n",
    "1. Initialize $\\delta_j$ (e.g., zeros)\n",
    "2. Given $\\delta_j$, compute choice probabilities and aggregate to $s_j^{\\text{pred}}$\n",
    "3. Update $\\delta_j$ using the contraction formula\n",
    "4. Check if the change in $\\delta_j$ is below a tolerance (e.g., $10^{-6}$)\n",
    "5. Repeat until convergence\n",
    "\n",
    "---\n",
    "\n",
    "### üìà Purpose\n",
    "\n",
    "- Recovers the mean utilities that exactly match observed market shares.\n",
    "- Forms the **core inner loop** of the BLP estimation algorithm.\n",
    "- Prepares for GMM estimation of random coefficient parameters (Practice 7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specification: define functions \n",
    "\n",
    "base_utility = pd.read_csv(\"simulated_utilities.csv\")\n",
    "delta_guess = [0,0,0,0,0]\n",
    "\n",
    "dataset = pd.read_csv(\"multi_market_data.csv\")\n",
    "\n",
    "market = dataset[dataset['market_id'] == 0].reset_index(drop=True) #extract multi market dataset\n",
    "\n",
    "observed_share = market['share'].values\n",
    "\n",
    "def predicted_share(input_utilities, input_delta): #output predicted shares \n",
    "    adjusted_utilities = input_utilities.values + input_delta\n",
    "    sum_utility = []\n",
    "    n_consumer = adjusted_utilities.shape[0]\n",
    "    n_product = adjusted_utilities.shape[1]\n",
    "    for i in range(n_consumer): \n",
    "        temp = 0\n",
    "        for j in range(n_product):\n",
    "            temp += np.exp(adjusted_utilities[i][j])\n",
    "        sum_utility.append(temp)\n",
    "    \n",
    "    prob_choice = adjusted_utilities.copy()\n",
    "    prob_choice = np.exp(prob_choice)\n",
    "    for i in range(n_consumer):\n",
    "        prob_choice[i] = prob_choice[i]/(sum_utility[i]+1)\n",
    "\n",
    "    pred_share = np.zeros(n_product)\n",
    "    for i in range(n_consumer):\n",
    "        for j in range(n_product):\n",
    "            pred_share[j] += prob_choice[i][j]\n",
    "    pred_share = pred_share/10\n",
    "    return pred_share\n",
    "\n",
    "\n",
    "adjusted_share = predicted_share(base_utility, delta_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our converged mean utilities are [ 0.238 -0.006 -0.04   0.015  0.063]\n"
     ]
    }
   ],
   "source": [
    "# Contraction mapping algorithm \n",
    "difference = 1\n",
    "delta_guess = [0,0,0,0,0]\n",
    "# we already have base utility and delta guess \n",
    "\n",
    "while difference > tolerance:    \n",
    "    adjusted_share = predicted_share(base_utility, delta_guess)\n",
    "    delta_new = delta_guess + np.log(observed_share) - np.log(adjusted_share)\n",
    "    difference = np.max(np.abs(delta_new - delta_guess))\n",
    "    # print(delta_guess, delta_new, difference)\n",
    "    delta_guess = delta_new\n",
    "\n",
    "print(\"our converged mean utilities are\", delta_guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Practice 7: GMM Estimation of Random Coefficients\n",
    "\n",
    "### üéØ Goal\n",
    "\n",
    "Estimate the random coefficient parameter $\\sigma$ (and linear parameters $\\beta$, $\\alpha$)  \n",
    "using the BLP GMM framework with moment conditions based on unobserved product characteristics $\\xi_{jt}$.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Theory\n",
    "\n",
    "The structural demand equation is:\n",
    "\n",
    "$$\n",
    "\\delta_{jt} = x_{jt} \\beta - \\alpha p_{jt} + \\xi_{jt}\n",
    "$$\n",
    "\n",
    "- You have already recovered $\\delta_{jt}$ from observed shares using contraction mapping.\n",
    "- The residual $\\xi_{jt}$ reflects unobserved demand shocks.\n",
    "- Valid instruments $z_{jt}$ should satisfy:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[z_{jt} \\cdot \\xi_{jt}] = 0\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è GMM Estimation Procedure\n",
    "\n",
    "1. **Fix a value of** $\\sigma$\n",
    "2. **Simulate** random coefficients for consumers using $\\sigma$\n",
    "3. **Solve** for $\\delta_{jt}$ using contraction mapping for each market\n",
    "4. **Estimate** $(\\beta, \\alpha)$ from:\n",
    "\n",
    "$$\n",
    "\\delta = X\\theta + \\xi, \\quad \\text{with instruments } Z\n",
    "$$\n",
    "\n",
    "5. **Compute residuals** $\\xi_{jt} = \\delta_{jt} - x_{jt} \\beta + \\alpha p_{jt}$\n",
    "6. **Form moment condition vector**:\n",
    "\n",
    "$$\n",
    "\\hat{g}(\\sigma) = \\frac{1}{N} \\sum z_{jt} \\cdot \\xi_{jt}\n",
    "$$\n",
    "\n",
    "7. **Compute GMM loss function**:\n",
    "\n",
    "$$\n",
    "Q(\\sigma) = \\hat{g}(\\sigma)^\\top W \\hat{g}(\\sigma)\n",
    "$$\n",
    "\n",
    "8. **Minimize** $Q(\\sigma)$ over values of $\\sigma$\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Notes\n",
    "\n",
    "- The outer loop optimizes $\\sigma$\n",
    "- The inner loop simulates demand and recovers $\\delta$ using contraction mapping\n",
    "- $W$ is the GMM weighting matrix (start with identity, refine iteratively)\n",
    "- Instruments $z_{jt}$ can include cost shifters, characteristics of rival products, etc.\n",
    "\n",
    "---\n",
    "\n",
    "### üìà Output\n",
    "\n",
    "- Estimated heterogeneity parameter $\\hat{\\sigma}$\n",
    "- Estimated linear parameters $\\hat{\\beta}$ and $\\hat{\\alpha}$\n",
    "- Residuals $\\hat{\\xi}_{jt}$, used for model fit and marginal cost recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice 7: Scaling it to multiple markets\n",
    "\n",
    "# we didn't creat an instrument for our simulated dataset\n",
    "# so now we will add in the instrument retroactively \n",
    "\n",
    "dataset = pd.read_csv(\"multi_market_data.csv\")\n",
    "dataset['z_rival_x'] = dataset.groupby('market_id')['x'].transform('sum') - dataset['x']\n",
    "dataset['z_rival_x'] = dataset['z_rival_x']/multim_n_consumer\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
